## The Parallel Images (ParIm) Dataset

Parellel Images (ParIm) (name pending) is a large-scale, massively multilingual dataset of images paired with the words they represent collected at the [University of Pennsylvania](https://upenn.edu).
The dataset is doubly parallel: for each language, its words are stored parallel to images that represent the word, _and_ parallel to the word's translation into English (and corresponding images.)

By far the largest dataset of its kind, with 100 languages and up to 10,000 words per language, it is useful for evaluating image-based translation methods.

## Getting Started

_Add: Short description of how to use a sample of the dataset_

See the [documentation page](doc.html)

## Downloads

Check out the [downloads](downloads.html) page for options on how to access the dataset. 

## Citation

If you use this dataset for your research, please cite:

Learning Translations via Images: A Large Multilingual Dataset and Comprehensive Study. <br>
John Hewitt\*, Daphne Ippolito\*, Brendan Callahan, Reno Kriz, Derry Tanti Wijaya and Chris Callison-Burch. <br>
ACL 2018. <br>

```
@InProceedings{hewitt-et-al:2018:Long,
  author    = {Hewitt, John  and  Ippolito, Daphne  and  Callahan, Brendan and Kriz, Reno and Wijaya, Derry Tanti and Callison-Burch, Chris},
  title     = {Learning Translations via Images: A Large Multilingual Dataset and Comprehensive Study.},
  booktitle = {Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  month     = {July},
  year      = {2018},
  address   = {Melbourne, Australia},
  publisher = {Association for Computational Linguistics}
}
```
